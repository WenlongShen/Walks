{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic: Machine Learning from Disaster\n",
    "\n",
    "### Overview\n",
    "\n",
    "Titanic是Kaggler的必经之路。作为一个完整的机器学习分析流程，本文主要介绍以下几个方面：\n",
    "\n",
    "    1) 问题分析\n",
    "    2) 数据整理\n",
    "    3) 特征工程\n",
    "    4) 模型建立\n",
    "    5) 模型集成\n",
    "    6) 系统优化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: 问题分析\n",
    "\n",
    "关于Titanic的相关描述可参考官网，这是一个二分类的基本问题。\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: 数据整理\n",
    "\n",
    "首先加载必要的库。数据这块儿用pandas，模型用scikit-learn和xgboost，计算的库numpy和scipy，作图用matplotlib和seaborn等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]\n",
      "pandas version: 0.23.4\n",
      "scikit-learn version: 0.20.0\n",
      "xgboost version: 0.81\n",
      "NumPy version: 1.13.3\n",
      "SciPy version: 1.1.0\n",
      "matplotlib version: 2.0.2\n",
      "seaborn version: 0.9.0\n",
      "IPython version: 5.3.0\n",
      "-------------------------\n",
      "gender_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: UTF-8 -*- \n",
    "#!/usr/bin/env python\n",
    "\n",
    "# system parameters\n",
    "import sys\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "# functions for data processing and analysis\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "# machine learning algorithms\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn import feature_selection, model_selection, metrics\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "print(\"xgboost version: {}\". format(xgboost.__version__))\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "# data visualization\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "from IPython import display\n",
    "print(\"matplotlib version: {}\". format(mpl.__version__))\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "print(\"IPython version: {}\". format(IPython.__version__))\n",
    "# Configure Visualization Defaults\n",
    "# %matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use(\"ggplot\")\n",
    "sns.set_style(\"white\")\n",
    "pylab.rcParams[\"figure.figsize\"] = 12,8\n",
    "\n",
    "# misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('-'*25)\n",
    "# Input data files are available in the \"datasets/titanic/\" directory.\n",
    "# Listing all files\n",
    "from subprocess import check_output\n",
    "data_dir = \"datasets/titanic/\"\n",
    "print(check_output([\"ls\", data_dir]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "接下来我们看看数据的基本情况，可以使用info、describe等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(data_dir+\"train.csv\")\n",
    "test = pd.read_csv(data_dir+\"test.csv\")\n",
    "train.info()\n",
    "#test.info()\n",
    "#train.describe(include = \"all\")\n",
    "#data_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人习惯将train和test合并做数据整理和特征工程，另外PassengerId仅仅用于数据标识，Ticket意义不太明确，我们将这两项去掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Age         1046 non-null float64\n",
      "Cabin       295 non-null object\n",
      "Embarked    1307 non-null object\n",
      "Fare        1308 non-null float64\n",
      "Name        1309 non-null object\n",
      "Parch       1309 non-null int64\n",
      "Pclass      1309 non-null int64\n",
      "Sex         1309 non-null object\n",
      "SibSp       1309 non-null int64\n",
      "Survived    891 non-null float64\n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 102.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# saving passenger id in advance in order to submit later.\n",
    "passengerId = test.PassengerId\n",
    "\n",
    "train_len = len(train)\n",
    "dataset =  pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "#dataset.info()\n",
    "#dataset.head()\n",
    "drop_column = [\"PassengerId\", \"Ticket\"]\n",
    "dataset.drop(drop_column, axis=1, inplace = True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "我们统计一下原数据中的缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns with null values:\n",
      " Age          263\n",
      "Cabin       1014\n",
      "Embarked       2\n",
      "Fare           1\n",
      "Name           0\n",
      "Parch          0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "SibSp          0\n",
      "Survived     418\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns with null values:\\n\", dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理缺失值是数据预处理重要的一环，往往要综合考虑，多次尝试。常见的方法除均值、中值、众值外，还包括关联性考察、重新编码、去除缺失值过多的特征项、利用机器学习赋值等。\n",
    "\n",
    "这里我们先看看Embarked特征项的两个缺失值，考察下Embarked特征项的整体情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Embarked\n",
       "S         914\n",
       "C         270\n",
       "Q         123\n",
       "NaN         2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Embarked.isnull()]\n",
    "pd.DataFrame(dataset.Embarked.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，出现频率最高的为S，所以一种处理方式就是将缺失值设为众数S。不过，仔细看下Embarked和Pclass/Fare之间的关系会发现，Pclass=1，Fare=80时，Embarked最有可能是C，所以这里我们也可将缺失值设为C。\n",
    "\n",
    "后续数据中，我们暂时用类似处理Embarked的方法填补Fare，用中值填补Age，用N填补Cabin。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.Embarked.fillna(\"C\", inplace=True)\n",
    "missing_value = dataset[(dataset.Pclass == 3) & (dataset.Embarked == \"S\") & (dataset.Sex == \"male\")].Fare.mean()\n",
    "dataset.Fare.fillna(missing_value, inplace=True)\n",
    "dataset.Age.fillna(dataset.Age.median(), inplace=True)\n",
    "dataset.Cabin.fillna(\"N\", inplace=True)\n",
    "dataset.info()\n",
    "dataset.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们简单看看train中各特征值之间的关系，包括与目标值Survived之间的关系等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = dataset[:train_len]\n",
    "#histogram comparison of sex, class, and age by survival\n",
    "h = sns.FacetGrid(data_plot, row = \"Sex\", col = \"Pclass\", hue = \"Survived\")\n",
    "h.map(plt.hist, \"Age\", alpha = .75)\n",
    "h.add_legend()\n",
    "#pair plots of entire dataset\n",
    "pp = sns.pairplot(data_plot, hue = \"Survived\", palette = \"deep\", size=1.2, diag_kind = \"kde\", diag_kws=dict(shade=True), plot_kws=dict(s=10) )\n",
    "pp.set(xticklabels=[])\n",
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={\"shrink\":.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor=\"white\",\n",
    "        annot_kws={\"fontsize\":12 }\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Pearson Correlation of Features\", y=1.05, size=15)\n",
    "correlation_heatmap(data_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: 特征工程\n",
    "\n",
    "特征工程可谓是个见仁见智见能力的事情。\n",
    "\n",
    "我们逐个特征项来做吧，首先是Age。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(data_plot.Age[data_plot.Survived == 0], color=\"Red\", shade = True)\n",
    "g = sns.kdeplot(data_plot.Age[data_plot.Survived == 1], ax =g, color=\"Blue\", shade= True)\n",
    "g.set_xlabel(\"Age\")\n",
    "g.set_ylabel(\"Frequency\")\n",
    "g = g.legend([\"Not Survived\",\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到整体差异不大，但儿童的生存率出现峰值，是人性的光辉吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"AgeBin\"] = pd.cut(dataset.Age.astype(int), 5)\n",
    "dataset[\"IsChild\"] = [1 if i<16 else 0 for i in dataset.Age]\n",
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin项描述了客舱编号，其开头字母可能具有信息，我们不妨抽提。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.Cabin.head()\n",
    "dataset.Cabin = [i[0] for i in dataset.Cabin]\n",
    "g = sns.factorplot(y=\"Survived\", x=\"Cabin\", data=dataset, kind=\"bar\")\n",
    "g = g.set_ylabels(\"Survival Probability\")\n",
    "#dataset = pd.get_dummies(dataset, columns = [\"Cabin\"], prefix=\"Cabin\")\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Fare，我们查看下分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(data_plot.Fare[data_plot.Survived == 0], color=\"Red\", shade = True)\n",
    "g = sns.kdeplot(data_plot.Fare[data_plot.Survived == 1], ax =g, color=\"Blue\", shade= True)\n",
    "g.set_xlabel(\"Fare\")\n",
    "g.set_ylabel(\"Frequency\")\n",
    "g = g.legend([\"Not Survived\",\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
